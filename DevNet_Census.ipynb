{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DevNet-Census.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1UWilAyX6R3ZVJJYJlW1ElYN_73Eg7fCe",
      "authorship_tag": "ABX9TyNTX5lOOKhYcUnRjew4Qt3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkt86/quant-notebooks/blob/master/DevNet_Census.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4YTLkp-Y6-4",
        "colab_type": "text"
      },
      "source": [
        "# DevNet \n",
        "\n",
        "Notebook, reproducing the results from Deep Anomaly Detection with Deviation Networks paper (https://paperswithcode.com/paper/deep-anomaly-detection-with-deviation)\n",
        "\n",
        "Model is applied on the Census dataset, available on https://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFufpLrEYfjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d67c0da-dee3-4156-f2a1-93733e0a5a39"
      },
      "source": [
        "%pip install tensorflow==1.10.1 keras==2.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/7e/a484776c73b1431f2b077e13801531e966113492552194fe721e6ef88d5d/tensorflow-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K     |████████████████████████████████| 58.4MB 52kB/s \n",
            "\u001b[?25hCollecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.31.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.34.2)\n",
            "Collecting tensorboard<1.11.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 34.1MB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.8.1)\n",
            "Collecting numpy<=1.14.5,>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 256kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (1.4.1)\n",
            "Collecting keras-applications==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (3.13)\n",
            "Collecting keras-preprocessing==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (3.1.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2020.7.24 has requirement numpy>=1.15.1, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.17.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0.1.post1 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorboard, setuptools, tensorflow, keras-applications, keras-preprocessing, keras\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: setuptools 49.2.0\n",
            "    Uninstalling setuptools-49.2.0:\n",
            "      Successfully uninstalled setuptools-49.2.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.14.5 setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFiCh3uZZG-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "216c6e4d-1a82-461e-c435-1e50ae99ed56"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 1.10.1\n",
            "Keras version: 2.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrFgH54Vbjzn",
        "colab_type": "text"
      },
      "source": [
        "### Load census data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCN_FmvOcDA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "005e83a8-68dc-4184-b109-5c7bf1e5fbe0"
      },
      "source": [
        "%%bash\n",
        "tar -xzvf drive/My\\ Drive/colab\\ data/census.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "census-income.data\n",
            "census-income.names\n",
            "census-income.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ6CugYccMXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "24051fbf-68a0-4e86-978a-e3ff721716a9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
        "\n",
        "# load training and testing data\n",
        "cols = [f\"X{i}\" for i in range(41)] + [\"target\"] \n",
        "train_data = pd.read_csv(\"census-income.data\", header=None, names=cols)\n",
        "test_data = pd.read_csv(\"census-income.test\", header=None, names=cols)\n",
        "\n",
        "# extract numerical and categorical columns\n",
        "num_cols, cat_cols = [], []\n",
        "for col in train_data.columns[:-1]:    \n",
        "  if pd.api.types.is_numeric_dtype(train_data[col]):\n",
        "    num_cols.append(col)\n",
        "  else:\n",
        "    cat_cols.append(col)\n",
        "\n",
        "  \n",
        "# create insample and outsample data\n",
        "insample_X = train_data[num_cols + cat_cols]\n",
        "insample_y = np.where(train_data[\"target\"] == \" - 50000.\", 0, 1)\n",
        "outsample_X = test_data[num_cols + cat_cols]\n",
        "outsample_y = np.where(test_data[\"target\"] == \" - 50000.\", 0, 1)\n",
        "\n",
        "# hotencode categorical values and scale data\n",
        "transformer = make_column_transformer(\n",
        "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
        "    (OneHotEncoder(), \n",
        "     make_column_selector(dtype_include=object)))\n",
        "\n",
        "insample_X = transformer.fit_transform(insample_X).todense()\n",
        "outsample_X = transformer.transform(outsample_X).todense()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Train data shape: {insample_X.shape}\")\n",
        "print(f\"Test data shape: {outsample_X.shape}\")\n",
        "print(f\"% positive values in train: {sum(insample_y)/len(insample_y)}\")\n",
        "print(f\"% positive values in test: {sum(outsample_y)/len(outsample_y)}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape: (199523, 409)\n",
            "Test data shape: (99762, 409)\n",
            "% positive values in train: 0.06205800834991455\n",
            "% positive values in test: 0.06200757803572503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPpGinqT2-i1",
        "colab_type": "text"
      },
      "source": [
        "### Create baseline model (RF classifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL94RCq11LW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "  print(f\"Precision : {precision_score(y_true, y_pred)}\")\n",
        "  print(f\"Recall    : {recall_score(y_true, y_pred)}\")\n",
        "  print(f\"F1-score  : {f1_score(y_true, y_pred)}\")\n",
        "  print(\"Confusion Matrix: \")\n",
        "  print(confusion_matrix(y_true, y_pred))  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5D8XVvm7ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1771af9f-40b1-493c-d0a1-1ddb8278832e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "known_outliers = 100\n",
        "outlier_indices = np.where(insample_y == 1)[0]\n",
        "n_outliers = len(outlier_indices)\n",
        "if n_outliers > known_outliers:\n",
        "    mn = n_outliers - known_outliers\n",
        "    remove_idx = rng.choice(outlier_indices, mn, replace=False)\n",
        "    rf_train_X = np.delete(insample_X, remove_idx, axis=0)\n",
        "    rf_train_y = np.delete(insample_y, remove_idx, axis=0)\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(rf_train_X, rf_train_y)\n",
        "outsample_rf_pred = rf.predict(outsample_X)\n",
        "print_metrics(outsample_y, outsample_rf_pred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 0.0\n",
            "Recall    : 0.0\n",
            "F1-score  : 0.0\n",
            "Confusion Matrix: \n",
            "[[93576     0]\n",
            " [ 6186     0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ob0oYZu7143",
        "colab_type": "text"
      },
      "source": [
        "### DevNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8dTTmVVlOkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "def dev_network_linear(input_shape):\n",
        "  '''\n",
        "  network architecture with no hidden layer, equivalent to linear mapping from\n",
        "  raw inputs to anomaly scores\n",
        "  '''    \n",
        "  x_input = Input(shape=input_shape)\n",
        "  intermediate = Dense(1, activation='linear',  name = 'score')(x_input)\n",
        "  return Model(x_input, intermediate)\n",
        "\n",
        "def dev_network_one(input_shape):\n",
        "  \"\"\"\n",
        "  network architecture with one hidden layer\n",
        "  \"\"\"\n",
        "  x_input = Input(shape=input_shape)\n",
        "  intermediate = Dense(20, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), name=\"hl1\")(x_input)\n",
        "  intermediate = Dense(1, activation=\"linear\", name=\"score\")(intermediate)\n",
        "  return Model(x_input, intermediate)\n",
        "\n",
        "def dev_network_two(input_shape):\n",
        "  \"\"\"\n",
        "  network architecture with two hidden layers\n",
        "  \"\"\"\n",
        "  x_input = Input(shape=input_shape)\n",
        "  intermediate = Dense(250, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), name=\"hl1\")(x_input)\n",
        "  intermediate = Dense(20, activation=\"relu\", kernel_regularizer=regularizers.l2(0.03), name=\"hl2\")(intermediate)\n",
        "  intermediate = Dense(1, activation=\"linear\", name=\"score\")(intermediate)\n",
        "  return Model(x_input, intermediate)\n",
        "\n",
        "def dev_network_three(input_shape):\n",
        "  \"\"\"\n",
        "  network architecture with three hidden layers\n",
        "  \"\"\"\n",
        "  x_input = Input(shape=input_shape)\n",
        "  intermediate = Dense(1000, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), name=\"hl1\")(x_input)\n",
        "  intermediate = Dense(250, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), name=\"hl2\")(intermediate)\n",
        "  intermediate = Dense(20, activation=\"relu\", kernel_regularizer=regularizers.l2(0.03), name=\"hl3\")(intermediate)\n",
        "  intermediate = Dense(1, activation=\"linear\", name=\"score\")(intermediate)\n",
        "  return Model(x_input, intermediate)\n",
        "\n",
        "def deviation_loss(y_true, y_pred):\n",
        "  '''\n",
        "  z-score-based deviation loss\n",
        "  '''    \n",
        "  confidence_margin = 5.     \n",
        "  ## size=5000 is the setting of l in algorithm 1 in the paper\n",
        "  ref = K.variable(np.random.normal(loc = 0., scale= 1.0, size = 5000) , dtype='float32')\n",
        "  dev = (y_pred - K.mean(ref)) / K.std(ref)\n",
        "  inlier_loss = K.abs(dev) \n",
        "  outlier_loss = K.abs(K.maximum(confidence_margin - dev, 0.))\n",
        "  return K.mean((1 - y_true) * inlier_loss + y_true * outlier_loss)\n",
        "\n",
        "def deviation_network(input_shape, network_depth):\n",
        "  '''\n",
        "  construct the deviation network-based detection model\n",
        "  '''\n",
        "  if network_depth == 4:\n",
        "      model = dev_network_three(input_shape)\n",
        "  elif network_depth == 3:\n",
        "      model = dev_network_two(input_shape)\n",
        "  elif network_depth == 2:\n",
        "      model = dev_network_one(input_shape)\n",
        "  elif network_depth == 1:\n",
        "      model = dev_network_linear(input_shape)\n",
        "  else:\n",
        "      sys.exit(\"The network depth is not set properly\")\n",
        "  rms = RMSprop(clipnorm=1.)\n",
        "  model.compile(loss=deviation_loss, optimizer=rms)\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbWe4F5p8BFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator_sup(x, outlier_indices, inlier_indices, batch_size, nb_batch, rng):\n",
        "  \"\"\"\n",
        "  batch generator\n",
        "  \"\"\"\n",
        "  rng = np.random.RandomState(rng.randint(MAX_INT, size = 1))\n",
        "  counter = 0\n",
        "  while 1:                \n",
        "    ref, training_labels = input_batch_generation_sup(x, outlier_indices, inlier_indices, batch_size, rng)\n",
        "    counter += 1\n",
        "    yield(ref, training_labels)\n",
        "    if (counter > nb_batch):\n",
        "        counter = 0\n",
        " \n",
        "def input_batch_generation_sup(x_train, outlier_indices, inlier_indices, batch_size, rng):\n",
        "    '''\n",
        "    batchs of samples. Alternates between positive and negative pairs.\n",
        "    '''      \n",
        "    dim = x_train.shape[1]\n",
        "    ref = np.empty((batch_size, dim))    \n",
        "    training_labels = []\n",
        "    n_inliers = len(inlier_indices)\n",
        "    n_outliers = len(outlier_indices)\n",
        "    for i in range(batch_size):    \n",
        "      if(i % 2 == 0):\n",
        "        sid = rng.choice(n_inliers, 1)\n",
        "        ref[i] = x_train[inlier_indices[sid]]\n",
        "        training_labels += [0.]\n",
        "      else:\n",
        "        sid = rng.choice(n_outliers, 1)\n",
        "        ref[i] = x_train[outlier_indices[sid]]\n",
        "        training_labels += [1.]\n",
        "    return np.array(ref), np.array(training_labels)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT7f4t_Q8Cvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "def aucPerformance(mse, labels):\n",
        "  roc_auc = roc_auc_score(labels, mse)\n",
        "  ap = average_precision_score(labels, mse)\n",
        "  print(\"AUC-ROC: %.4f, AUC-PR: %.4f\" % (roc_auc, ap))\n",
        "  return roc_auc, ap;"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68aSEdyA8ETq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model_weight_predict(model_name, input_shape, network_depth, x_test):\n",
        "  '''\n",
        "  load the saved weights to make predictions\n",
        "  '''\n",
        "  model = deviation_network(input_shape, network_depth)\n",
        "  model.load_weights(model_name)\n",
        "  scoring_network = Model(inputs=model.input, outputs=model.output)    \n",
        "  scores = scoring_network.predict(x_test)\n",
        "  return scores"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1WjrSZ9-SNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inject_noise(seed, n_out, random_seed):\n",
        "  \"\"\"\n",
        "  add anomalies to training data to replicate anomaly contaminated data sets.\n",
        "  we randomly swape 5% features of anomalies to avoid duplicate contaminated anomalies.\n",
        "  this is for dense data\n",
        "  \"\"\"\n",
        "  rng = np.random.RandomState(random_seed) \n",
        "  n_sample, dim = seed.shape\n",
        "  swap_ratio = 0.05\n",
        "  n_swap_feat = int(swap_ratio * dim)\n",
        "  noise = np.empty((n_out, dim))\n",
        "  for i in np.arange(n_out):\n",
        "    outlier_idx = rng.choice(n_sample, 2, replace = False)\n",
        "    o1 = seed[outlier_idx[0]]\n",
        "    o2 = seed[outlier_idx[1]]\n",
        "    swap_feats = rng.choice(dim, n_swap_feat, replace = False)\n",
        "    noise[i] = o1.copy()\n",
        "    #noise[i, swap_feats] = o2[swap_feats]\n",
        "    noise[i, swap_feats] = o2[0, swap_feats]\n",
        "  return noise"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiwhgNEhAR7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "557206a4-5c8c-4436-e2a8-473ad8f107b6"
      },
      "source": [
        "%%bash\n",
        "mkdir model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67ivFolF8Fw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "35210759-9663-4942-f2ee-7c305427a4be"
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MAX_INT = np.iinfo(np.int32).max\n",
        "\n",
        "batch_size = 512      # batch size used in SGD\n",
        "cont_rate = 0.02      # the outlier contamination rate in the training data\n",
        "epochs = 50           # the number of epochs\n",
        "known_outliers = 100  # the number of labeled outliers available at hand\"\n",
        "nb_batch = 20         # the number of batches per epoch\n",
        "network_depth = 2     # the depth of the network architecture\n",
        "random_seed = 42      # random seed number\n",
        "runs = 5             # how many times we repeat the experiments to obtain the average performance\n",
        "\n",
        "outlier_indices = np.where(insample_y == 1)[0]\n",
        "outliers = insample_X[outlier_indices]  \n",
        "n_outliers_org = outliers.shape[0] \n",
        "\n",
        "rng = np.random.RandomState(random_seed)\n",
        "rauc = np.zeros(runs)\n",
        "ap = np.zeros(runs) \n",
        "\n",
        "for run in np.arange(runs):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(insample_X, insample_y, \n",
        "                                                      test_size=0.2, \n",
        "                                                      random_state=random_seed, \n",
        "                                                      stratify=insample_y)\n",
        "  y_train = np.array(y_train)\n",
        "  y_test = np.array(y_test)\n",
        "  outlier_indices = np.where(y_train == 1)[0]\n",
        "  inlier_indices = np.where(y_train == 0)[0]\n",
        "  n_outliers = len(outlier_indices)\n",
        "  \n",
        "  n_noise = len(np.where(y_train == 0)[0])*cont_rate / (1. - cont_rate)\n",
        "  n_noise = int(n_noise)\n",
        "\n",
        "  rng = np.random.RandomState(random_seed)\n",
        "\n",
        "  # keep maximum number of outliers below 30 (try removing this)\n",
        "  if n_outliers > known_outliers:\n",
        "    mn = n_outliers - known_outliers\n",
        "    remove_idx = rng.choice(outlier_indices, mn, replace=False)\n",
        "    x_train = np.delete(x_train, remove_idx, axis=0)\n",
        "    y_train = np.delete(y_train, remove_idx, axis=0)\n",
        "\n",
        "  noises = inject_noise(outliers, n_noise, random_seed)\n",
        "  x_train = np.append(x_train, noises, axis=0)\n",
        "  y_train = np.append(y_train, np.zeros((noises.shape[0], 1)))\n",
        "\n",
        "  outlier_indices = np.where(y_train == 1)[0]\n",
        "  inlier_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "  input_shape = x_train.shape[1:]\n",
        "  n_samples_trn = x_train.shape[0]\n",
        "  n_outliers = len(outlier_indices)            \n",
        "\n",
        "  start_time = time.time()\n",
        "  input_shape = x_train.shape[1:]\n",
        "  model = deviation_network(input_shape, network_depth)\n",
        "  model_name = \"./model/devnet_\" + str(cont_rate) + \"cr_\"  + str(batch_size) +\"bs_\" + str(known_outliers) + \"ko_\" + str(network_depth) +\"d.h5\"\n",
        "  checkpointer = ModelCheckpoint(model_name, monitor='loss', verbose=0, save_best_only = True, save_weights_only = True)\n",
        "\n",
        "  model.fit_generator(batch_generator_sup(x_train, outlier_indices, inlier_indices, batch_size, nb_batch, rng), \n",
        "                      steps_per_epoch = nb_batch,\n",
        "                      epochs = epochs,\n",
        "                      callbacks=[checkpointer], verbose=0) \n",
        "  train_time = time.time() - start_time\n",
        "\n",
        "  start_time = time.time()\n",
        "  scores = load_model_weight_predict(model_name, input_shape, network_depth, x_test)\n",
        "  test_time = time.time() - start_time\n",
        "  rauc[run], ap[run] = aucPerformance(scores, y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC-ROC: 0.9100, AUC-PR: 0.5230\n",
            "AUC-ROC: 0.9116, AUC-PR: 0.5273\n",
            "AUC-ROC: 0.9112, AUC-PR: 0.5185\n",
            "AUC-ROC: 0.9131, AUC-PR: 0.5220\n",
            "AUC-ROC: 0.9156, AUC-PR: 0.5196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6SDnjtjFgYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ba5fc2fe-1332-46ce-91b3-d6b0f30439b6"
      },
      "source": [
        "outsample_scores = load_model_weight_predict(model_name, input_shape, network_depth, outsample_X)\n",
        "outsample_pred = np.where(outsample_scores >= 5., 1, 0)\n",
        "print_metrics(outsample_y, outsample_pred)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 0.5717740162673115\n",
            "Recall    : 0.4204655674102813\n",
            "F1-score  : 0.4845831392640894\n",
            "Confusion Matrix: \n",
            "[[91628  1948]\n",
            " [ 3585  2601]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kdnMM-UFkg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[[92843   733]\n",
        " [ 3821  2365]]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}